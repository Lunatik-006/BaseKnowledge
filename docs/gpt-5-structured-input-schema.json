{
  "type": "object",
  "title": "Input",
  "properties": {
    "model": {
      "enum": [
        "gpt-5",
        "gpt-5-mini",
        "gpt-5-nano"
      ],
      "type": "string",
      "title": "model",
      "description": "GPT-5 model to use.",
      "default": "gpt-5",
      "x-order": 0
    },
    "tools": {
      "type": "array",
      "items": {
        "type": "object"
      },
      "title": "Tools",
      "default": [],
      "x-order": 10,
      "description": "Tools to make available to the model. Should be a JSON object containing a list of tool definitions."
    },
    "prompt": {
      "type": "string",
      "title": "Prompt",
      "x-order": 1,
      "nullable": true,
      "description": "A simple text input to the model, equivalent to a text input with the user role. Ignored if input_item_list is provided."
    },
    "verbosity": {
      "enum": [
        "low",
        "medium",
        "high"
      ],
      "type": "string",
      "title": "verbosity",
      "description": "Constrains the verbosity of the model's response. Lower values will result in more concise responses, while higher values will result in more verbose responses. Currently supported values are low, medium, and high. GPT-5 supports this parameter to help control whether answers are short and to the point or long and comprehensive.",
      "default": "medium",
      "x-order": 5
    },
    "image_input": {
      "type": "array",
      "items": {
        "type": "string",
        "format": "uri"
      },
      "title": "Image Input",
      "default": [],
      "x-order": 3,
      "description": "List of images to send to the model"
    },

    /* ⬇⬇⬇ UPDATED: use response_format (Structured Outputs) instead of top-level json_schema ⬇⬇⬇ */
    "response_format": {
      "type": "object",
      "title": "Response Format",
      "x-order": 11,
      "nullable": true,
      "description": "Structured outputs configuration (OpenAI Responses API compatible). To enforce a JSON Schema, set: { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"...\", \"strict\": true, \"schema\": { ... } } }",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["json_schema"],
          "title": "Response format type",
          "description": "Use \"json_schema\" to enforce structured JSON outputs."
        },
        "json_schema": {
          "type": "object",
          "title": "JSON Schema container",
          "description": "Container for the JSON Schema definition as per OpenAI Structured Outputs.",
          "properties": {
            "name": {
              "type": "string",
              "title": "Schema name",
              "description": "Arbitrary name for the schema."
            },
            "strict": {
              "type": "boolean",
              "title": "Strict",
              "description": "If true, the model must return output strictly conforming to the schema.",
              "default": true
            },
            "schema": {
              "type": "object",
              "title": "Schema",
              "description": "A valid JSON Schema object (Draft-07/2020-12 compatible)."
            }
          },
          "required": ["name", "schema"]
        }
      },
      "required": ["type", "json_schema"]
    },
    /* ⬆⬆⬆ END of update ⬆⬆⬆ */

    "instructions": {
      "type": "string",
      "title": "Instructions",
      "x-order": 2,
      "nullable": true,
      "description": "A system (or developer) message inserted into the model's context. When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses."
    },
    "simple_schema": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "title": "Simple Schema",
      "default": [],
      "x-order": 7,
      "description": "Create a JSON schema for the output to conform to. The schema will be created from a simple list of field specifications. Strings: 'thing' (defaults to string), 'thing:str', 'thing:string'. Booleans: 'is_a_thing:bool' or 'is_a_thing:boolean'. Numbers: 'count:number', 'count:int'. Lists: 'things:list' (defaults to list of strings), 'things:list:str', 'number_things:list:number', etc. Nested objects are not supported, use response_format.json_schema instead."
    },
    "input_item_list": {
      "type": "array",
      "items": {
        "type": "object"
      },
      "title": "Input Item List",
      "default": [],
      "x-order": 8,
      "description": "A list of one or many input items to the model, containing different content types. This parameter corresponds with the `input` OpenAI API parameter. For more details see: https://platform.openai.com/docs/api-reference/responses/create#responses_create-input. Similar to the `messages` parameter, but with more flexibility in the content types."
    },
    "reasoning_effort": {
      "enum": [
        "minimal",
        "low",
        "medium",
        "high"
      ],
      "type": "string",
      "title": "reasoning_effort",
      "description": "Constrains effort on reasoning for GPT-5 models. Currently supported values are minimal, low, medium, and high. The minimal value gets answers back faster without extensive reasoning first. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response. For higher reasoning efforts you may need to increase your max_completion_tokens to avoid empty responses (where all the tokens are used on reasoning).",
      "default": "minimal",
      "x-order": 4
    },
    "enable_web_search": {
      "type": "boolean",
      "title": "Enable Web Search",
      "default": false,
      "x-order": 6,
      "description": "Allow GPT-5 to use web search for the response."
    },
    "max_output_tokens": {
      "type": "integer",
      "title": "Max Output Tokens",
      "x-order": 12,
      "nullable": true,
      "description": "Maximum number of completion tokens to generate. For higher reasoning efforts you may need to increase your max_completion_tokens to avoid empty responses (where all the tokens are used on reasoning)."
    },
    "previous_response_id": {
      "type": "string",
      "title": "Previous Response Id",
      "x-order": 9,
      "nullable": true,
      "description": "The ID of a previous response to continue from."
    }
  }
}
